# ðŸš€ INICIO RÃPIDO - Clinical Assistant

## Para empezar AHORA MISMO:

### OpciÃ³n 1: Docker (Recomendado) ðŸ³

```bash
# 1. Crear archivo .env con tu token de HuggingFace
echo "HF_TOKEN=tu_token_aqui" > .env

# 2. Iniciar (descarga, construye e inicia todo)
docker-compose up --build

# 3. Abrir navegador
http://localhost:8000
```

**Â¡Listo!** La aplicaciÃ³n estarÃ¡ corriendo en http://localhost:8000

---

### OpciÃ³n 2: Local (Desarrollo) ðŸ’»

```bash
# 1. Ejecutar script de inicio
./start.sh

# 2. Abrir navegador
http://localhost:8000
```

El script se encarga de:
- âœ… Crear virtualenv
- âœ… Instalar dependencias
- âœ… Iniciar la aplicaciÃ³n

---

## ðŸ“ Notas Importantes

### Primera Vez
- La primera peticiÃ³n tarda **30-60 segundos** (carga modelos)
- Las siguientes son **mucho mÃ¡s rÃ¡pidas** (5-10 segundos)

### Requisitos MÃ­nimos
- Python 3.11+ (para local)
- Docker (para Docker)
- 8GB RAM mÃ­nimo
- Token de HuggingFace

### Token de HuggingFace
1. Ir a https://huggingface.co/settings/tokens
2. Crear nuevo token (lectura)
3. Aceptar licencia de Llama 3.2
4. AÃ±adir a `.env`

---

## ðŸ”§ Comandos Ãštiles

### Docker
```bash
# Iniciar
docker-compose up

# Detener
docker-compose down

# Ver logs
docker-compose logs -f

# Reconstruir
docker-compose up --build
```

### Local
```bash
# Iniciar
./start.sh

# O manualmente:
cd backend
source venv/bin/activate
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

---

## ðŸ“š MÃ¡s InformaciÃ³n

- **README completo**: `README.md`
- **DocumentaciÃ³n tÃ©cnica**: `docs/`
- **API Docs**: http://localhost:8000/docs

---

## â“ Problemas Comunes

### "Models not found"
â†’ Verifica que existan:
- `backend/models/classifier/`
- `backend/models/t5_summarizer/`
- `backend/models/llama_peft/`

### "HF_TOKEN not set"
â†’ Crea archivo `.env`:
```bash
echo "HF_TOKEN=hf_tu_token" > .env
```

### Puerto 8000 ocupado
â†’ Cambia el puerto:
```bash
uvicorn app.main:app --port 8001
```

---

**Â¡Eso es todo! El proyecto estÃ¡ listo para usar.** ðŸŽ‰
