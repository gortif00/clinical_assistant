# ğŸ§  Clinical Mental Health Assistant

> **AI-Powered Diagnostic Support Tool for Mental Health Professionals**

An intelligent system that provides automated mental health condition classification and evidence-based treatment recommendations based on clinical case descriptions.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green.svg)](https://fastapi.tiangolo.com/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Tests](https://img.shields.io/badge/Tests-25%20passing-success.svg)](tests/)
[![Coverage](https://img.shields.io/badge/Coverage-70%25-green.svg)](tests/)
[![Production Ready](https://img.shields.io/badge/Production-Ready-brightgreen.svg)](docs/DEPLOYMENT.md)

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
  - [Docker Deployment](#-docker-deployment-recommended)
  - [Local Development](#-local-development)
- [Production Features](#-production-features)
- [Project Structure](#-project-structure)
- [API Documentation](#-api-documentation)
- [Configuration](#-configuration)
- [Testing](#-testing)
- [Deployment](#-deployment)
- [Monitoring](#-monitoring)
- [Troubleshooting](#-troubleshooting)
- [Documentation](#-documentation)
- [Disclaimer](#ï¸-important-disclaimer)

---

## ğŸ¯ Overview

The Clinical Mental Health Assistant is a **unified full-stack application** that leverages three state-of-the-art NLP models:

| Component | Model | Purpose | Performance |
|-----------|-------|---------|-------------|
| **Classification** | BERT (110M params) | Diagnose mental health conditions | 204K training samples |
| **Summarization** | T5-base (220M params) | Extract clinical summaries | ROUGE-2: 14.72% |
| **Generation** | Llama 3.2-1B + LoRA | Generate treatment recommendations | Perplexity: 6.15 |

### âœ¨ Key Features

- âœ… **Unified Deployment**: Single command launch - no separate frontend/backend
- âš¡ **High Performance**: 60-80% faster inference with optimized model loading
- ğŸ”’ **Privacy-First**: All processing runs locally, no external API calls
- ğŸ¯ **Professional UI**: Clean, medical-grade interface
- ğŸ“Š **Real-time Status**: Device monitoring (CUDA/MPS/CPU)
- ğŸ³ **Docker Ready**: Production-ready containerized deployment

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              FastAPI Application (Port 8000)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Frontend (/)              â”‚  Backend API (/api/v1)          â”‚
â”‚  - HTML/CSS/JS             â”‚  - /analyze (POST)              â”‚
â”‚  - Served by FastAPI       â”‚  - /health (GET)                â”‚
â”‚                            â”‚  - /get_status (GET)            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚              Model Manager (Singleton Pattern)               â”‚
â”‚  â€¢ Lazy Loading            â”‚  â€¢ Device Auto-detection        â”‚
â”‚  â€¢ Model Caching           â”‚  â€¢ Unified Pipeline             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Design Principles:**
- **Unified Stack**: Frontend and backend served from single FastAPI instance
- **Singleton Pattern**: Models loaded once and reused across requests
- **Lazy Loading**: Models load only when needed, with caching
- **Zero Config**: Automatic device detection (CUDA/MPS/CPU)

---

## ğŸš€ Quick Start

### ğŸ³ Docker Deployment (Recommended)

**Perfect for production or if you want zero setup hassle.**

```bash
# 1. Clone the repository
git clone https://github.com/gortif00/clinical_assistant.git
cd clinical_assistant

# 2. Create .env file with your HuggingFace token (required for Llama)
echo "HF_TOKEN=your_huggingface_token_here" > .env

# 3. Launch the application
docker-compose up --build

# 4. Access the application
# Open your browser at: http://localhost:8000
```

**That's it!** The application will:
- âœ… Install all dependencies automatically
- âœ… Load models on first request (takes ~30-60s)
- âœ… Serve both frontend and API from port 8000
- âœ… Cache models for fast subsequent requests

**Stopping the application:**
```bash
docker-compose down
```

---

### ğŸ’» Local Development

**For development or if you prefer running without Docker.**

#### Prerequisites

- Python 3.11+
- pip and virtualenv
- HuggingFace account and token
- 8GB+ RAM (16GB recommended)
- GPU optional but recommended

#### Step-by-Step Setup

```bash
# 1. Clone and navigate
git clone https://github.com/gortif00/clinical_assistant.git
cd clinical_assistant

# 2. Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
cd backend
pip install -r requirements.txt

# 4. Set HuggingFace token
export HF_TOKEN="your_huggingface_token_here"

# 5. Run the application
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# 6. Access the application
# Open your browser at: http://localhost:8000
```

**Development Tips:**
- Use `--reload` flag for auto-restart on code changes
- Check logs for model loading progress
- First request takes 30-60s (loads all models)
- Subsequent requests are 5-10s (uses cached models)

---

## ğŸš€ Production Features

This application is **production-ready** with enterprise-grade features:

### Security & Authentication
- âœ… **Rate Limiting**: Configurable limits per tier (anonymous/authenticated/premium)
- âœ… **JWT Authentication**: Token-based auth with access/refresh tokens
- âœ… **Password Hashing**: Secure bcrypt password storage
- âœ… **CORS Configuration**: Configurable cross-origin policies

### Monitoring & Observability
- âœ… **Prometheus Metrics**: Exposed on `/metrics` endpoint
  - HTTP request counts, duration, errors
  - Model inference time and memory usage
  - System metrics (CPU, memory, disk, GPU)
- âœ… **Structured Logging**: JSON logs with request tracking
- âœ… **Health Checks**: Multiple probe types for Kubernetes
  - `/api/v1/health` - Basic health
  - `/api/v1/health/detailed` - Full system status
  - `/api/v1/health/ready` - Readiness probe
  - `/api/v1/health/live` - Liveness probe

### Testing & Quality
- âœ… **25 Automated Tests**: Unit + Integration tests
- âœ… **70%+ Coverage**: Comprehensive test coverage
- âœ… **pytest Configuration**: Ready to run with `pytest`

### CI/CD & Deployment
- âœ… **GitHub Actions Pipeline**: 4-stage automated deployment
  - Test (linting, type checking, pytest)
  - Security (Trivy, Safety, Bandit)
  - Build (Docker multi-platform)
  - Deploy (Kubernetes rolling update)
- âœ… **Kubernetes Manifests**: Production-ready K8s configs
  - Deployment with HPA (auto-scaling 3-10 pods)
  - Ingress with TLS (cert-manager)
  - Redis for distributed rate limiting
  - Prometheus + Grafana monitoring

### Documentation
- ğŸ“š **Comprehensive Guides**: 1200+ lines of documentation
  - [Deployment Guide](docs/DEPLOYMENT.md) - Complete deployment instructions
  - [Production README](docs/README_PRODUCTION.md) - Professional overview
  - [Implementation Summary](docs/PRODUCTION_IMPLEMENTATION.md) - Technical details
  - [Integration Complete](docs/INTEGRATION_COMPLETE.md) - Status & next steps

**Quick Links:**
- Run tests: `pytest`
- View metrics: http://localhost:8000/metrics
- Check health: http://localhost:8000/api/v1/health/detailed
- API docs: http://localhost:8000/docs

---

## ğŸ“ Project Structure

```
clinical_assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/
â”‚   â”‚   â”‚   â”œâ”€â”€ analyze.py          # Analysis endpoints
â”‚   â”‚   â”‚   â””â”€â”€ health.py           # Health checks âœ¨
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â”‚   â”‚   â””â”€â”€ logging_config.py   # Structured logging âœ¨
â”‚   â”‚   â”œâ”€â”€ middleware/             # Production middleware âœ¨
â”‚   â”‚   â”‚   â”œâ”€â”€ rate_limiter.py
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ ml/
â”‚   â”‚   â”‚   â”œâ”€â”€ models_loader.py    # Model Manager (optimized)
â”‚   â”‚   â”‚   â””â”€â”€ pipeline.py
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ text_cleaning.py
â”‚   â”‚   â”œâ”€â”€ main.py                 # FastAPI app (production-ready)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/                     # Trained models
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ requirements-dev.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ images/favicon.svg          # Custom favicon âœ¨
â”‚   â”œâ”€â”€ css/styles.css
â”‚   â””â”€â”€ js/app.js
â”œâ”€â”€ tests/                          # Automated tests âœ¨
â”‚   â”œâ”€â”€ conftest.py
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ integration/
â”œâ”€â”€ k8s/                            # Kubernetes manifests âœ¨
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .github/workflows/              # CI/CD pipeline âœ¨
â”‚   â””â”€â”€ ci-cd.yml
â”œâ”€â”€ docs/                           # Documentation âœ¨
â”‚   â”œâ”€â”€ DEPLOYMENT.md
â”‚   â”œâ”€â”€ README_PRODUCTION.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ pytest.ini                      # Test config âœ¨
â”œâ”€â”€ test_endpoints.sh               # Test script âœ¨
â”œâ”€â”€ run_server.py
â”œâ”€â”€ .env.example                    # Environment template âœ¨
â””â”€â”€ README.md

âœ¨ = New production features
```

**Key Files:**
- `backend/app/main.py`: FastAPI app that serves both frontend and API
- `backend/app/ml/models_loader.py`: Optimized model manager with singleton pattern
- `frontend/`: Static frontend files (HTML/CSS/JS)
- `docker-compose.yml`: Single-command deployment configuration

---

## ğŸ“š API Documentation

Once the application is running, visit:

- **Interactive API Docs**: http://localhost:8000/docs
- **Alternative Docs**: http://localhost:8000/redoc

### Main Endpoints

#### `POST /api/v1/analyze`

Analyze a clinical case and generate recommendations.

**Request Body:**
```json
{
  "text": "Patient clinical observations...",
  "auto_classify": true,
  "pathology": null
}
```

**Response:**
```json
{
  "classification": {
    "pathology": "Major Depressive Disorder",
    "confidence": 0.87,
    "all_probabilities": {...}
  },
  "summary": "Clinical summary...",
  "recommendation": "Treatment recommendation...",
  "metadata": {
    "processing_time": 7.32
  }
}
```

#### `GET /api/v1/get_status`

Get execution device status (CUDA/MPS/CPU).

**Response:**
```json
{
  "status": "ok",
  "device": "mps"
}
```

#### `GET /api/v1/health`

Check if models are loaded and ready.

**Response:**
```json
{
  "status": "healthy",
  "models_loaded": true
}
```

---

## ğŸ§ª Testing

Run the automated test suite:

```bash
# Install dev dependencies
pip install -r backend/requirements-dev.txt

# Run all tests
pytest

# Run with coverage
pytest --cov=backend --cov-report=html

# Run specific test categories
pytest tests/unit/              # Unit tests only
pytest tests/integration/       # Integration tests only

# Test specific endpoint
./test_endpoints.sh
```

**Test Coverage:**
- Rate limiting (6 tests)
- JWT authentication (7 tests)
- API endpoints (12 tests)
- **Total: 25 tests**

---

## ğŸ“¦ Deployment

### Local Production

```bash
# 1. Setup environment
cp .env.example .env
# Edit .env with your values

# 2. Install dependencies
pip install -r backend/requirements.txt

# 3. Run server
python run_server.py
```

### Docker

```bash
docker-compose up --build
```

### Kubernetes

```bash
# See complete guide in docs/DEPLOYMENT.md

# Quick start:
kubectl create namespace production
kubectl apply -f k8s/secrets.yaml
kubectl apply -f k8s/
```

**Production Checklist:**
- [ ] Change JWT secrets (`.env`)
- [ ] Configure CORS origins
- [ ] Enable HTTPS/TLS
- [ ] Setup Redis for rate limiting
- [ ] Configure monitoring
- [ ] Setup CI/CD secrets in GitHub

See [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) for complete deployment guide.

---

## ğŸ“Š Monitoring

### Health Checks

```bash
# Basic health
curl http://localhost:8000/api/v1/health

# Detailed system status
curl http://localhost:8000/api/v1/health/detailed

# Kubernetes probes
curl http://localhost:8000/api/v1/health/ready
curl http://localhost:8000/api/v1/health/live
```

### Metrics

Prometheus metrics exposed on `/metrics`:

```bash
# View metrics
curl http://localhost:8000/metrics

# Key metrics:
# - http_requests_total
# - http_request_duration_seconds
# - model_inference_duration_seconds
# - errors_total
```

### Grafana Dashboard

Import `k8s/grafana-dashboard.json` for:
- Request rate & latency (p95, p99)
- Error rates
- Model performance
- System resources (CPU, memory, GPU)
- Pod health

---

## âš™ï¸ Configuration

### Environment Variables

Create a `.env` file in the project root:

```bash
# Required: HuggingFace token for Llama model access
HF_TOKEN=your_token_here

# Optional: Advanced settings (defaults work fine)
# CLASSIFICATION_MODEL_PATH=backend/models/classifier
# T5_SUMMARIZATION_PATH=backend/models/t5_summarizer
# LLAMA_MODEL_CHECKPOINT=meta-llama/Llama-3.2-1B-Instruct
```

### Getting a HuggingFace Token

1. Go to https://huggingface.co/settings/tokens
2. Create a new token (read access is sufficient)
3. Accept Llama model license at https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct
4. Add token to `.env` file

---

## ğŸ”§ Troubleshooting

### Common Issues

#### "Models not loaded" error
**Cause**: Models directory is empty or models failed to load.

**Solution**:
```bash
# Check if models exist
ls -lh backend/models/

# If missing, you need to train models first
# See docs/SYSTEM_VERIFICATION_REPORT.md for training instructions
```

#### First request is very slow (30-60s)
**Cause**: This is normal! Models are loading for the first time.

**Expected behavior**:
- First request: 30-60s (loads BERT + T5 + Llama)
- Second request: 5-10s (uses cached models)

#### "Frontend not showing device" or CORS errors
**Cause**: Backend might not be running or accessible.

**Solution**:
```bash
# Check backend is running
curl http://localhost:8000/api/v1/health

# Check logs for errors
docker-compose logs -f  # For Docker
# or check terminal output for local deployment
```

#### Docker build fails with "disk space" error
**Cause**: Docker models are large (~2GB).

**Solution**:
```bash
# Clean old images
docker system prune -a

# Use volume mounting (already configured in docker-compose.yml)
# Models will be loaded from ./backend/models instead of copied into image
```

### Performance Issues

If inference is slow even after first request:

1. **Check device**: Visit http://localhost:8000 - should show GPU if available
2. **Check logs**: Look for "âš¡ Already loaded, skip" messages (should appear on 2nd+ requests)
3. **Verify RAM**: Ensure you have 8GB+ free RAM
4. **GPU drivers**: For CUDA, ensure nvidia-docker is installed

---

## ğŸ“– Documentation

Additional documentation is available in the `docs/` directory:

- **[REPORT_SUMMARY.md](docs/REPORT_SUMMARY.md)**: Project overview and model details
- **[SYSTEM_VERIFICATION_REPORT.md](docs/SYSTEM_VERIFICATION_REPORT.md)**: Technical deep dive
- **[SPEED_OPTIMIZATIONS.md](docs/SPEED_OPTIMIZATIONS.md)**: Performance improvements explained

---

## âš ï¸ Important Disclaimer

**This system is a clinical decision support tool designed for licensed mental health professionals.**

- âœ… **Intended Use**: Augment professional clinical judgment
- âŒ **Not a Replacement**: Does not replace comprehensive clinical assessment
- ğŸ”’ **Professional Only**: For use by qualified healthcare providers
- ğŸ“‹ **Final Diagnosis**: Must incorporate patient history and professional expertise

**This tool should never be used as the sole basis for diagnosis or treatment decisions.**

---

## ğŸ“„ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

- **Models**: BERT, T5, and Llama from HuggingFace Transformers
- **Framework**: FastAPI for unified backend/frontend serving
- **Optimization**: Inspired by efficient model management patterns

---

## ğŸ“§ Contact

For questions or issues:
- Open an issue on [GitHub](https://github.com/gortif00/clinical_assistant/issues)
- Check existing documentation in `docs/`

---

**Made with â¤ï¸ for Mental Health Professionals**
